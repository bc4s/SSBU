data <- read.csv("diabetes.csv")
head(data)  # View the first few rows of the data
View(data)
View(data)
head(data)  # View the first few rows of the data
summary(data)  # Summary statistics of the variables
predictors <- data[, c("Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI", "DiabetesPedigreeFunction", "Age")]
View(predictors)
View(data)
outcome <- data$Outcome
set.seed(123)  # For reproducibility
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data), nrow(data) * 0.7)  # 70% for training
train_data <- predictors[train_indices, ]
train_outcome <- outcome[train_indices]
test_data <- predictors[-train_indices, ]
test_outcome <- outcome[-train_indices]
model <- glm(Outcome ~ ., data = data, family = binomial(link = "logit"))
predicted <- predict(model, newdata = test_data, type = "response")
View(train_data)
View(predictors)
# For example, you can calculate the accuracy
accuracy <- sum(round(predicted) == test_outcome) / length(predicted)
train_indices <- sample(1:nrow(data), nrow(data) * 0.8)  # 70% for training
train_data <- predictors[train_indices, ]
train_outcome <- outcome[train_indices]
test_data <- predictors[-train_indices, ]
test_outcome <- outcome[-train_indices]
model <- glm(Outcome ~ ., data = data, family = binomial(link = "logit"))
predicted <- predict(model, newdata = test_data, type = "response")
# For example, you can calculate the accuracy
accuracy <- sum(round(predicted) == test_outcome) / length(predicted)
# For example, you can calculate the accuracy
accuracy <- sum(round(predicted) == test_outcome) / length(predicted)
set.seed(123)  # For reproducibility
# For example, you can calculate the accuracy
accuracy <- sum(round(predicted) == test_outcome) / length(predicted)
coefs <- coef(model)[-1]  # Exclude the intercept
coef_df <- data.frame(variable = names(coefs), coefficient = coefs)
ggplot(coef_df, aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "steelblue") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
install.packages("ggplot2")  # For data visualization
install.packages("dplyr")    # For data manipulation
install.packages("glmnet")   # For logistic regression
ggplot(coef_df, aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "steelblue") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
library(ggplot2)
library(dplyr)
library(glmnet)
ggplot(coef_df, aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "steelblue") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
summary(data)  # Summary statistics of the variables
head(data)  # View the first few rows of the data
head(data)  # View the first few rows of the data
data <- read.csv("diabetes.csv")
summary(data)  # Summary statistics of the variables
head(data)  # View the first few rows of the data
summary(data)  # Summary statistics of the variables
View(predictors)
View(predictors)
View(test_data)
train_indices <- sample(1:nrow(data), nrow(data) * 0.8)
train_data <- x_values[train_indices, ]
train_indices <- sample(1:nrow(data), nrow(data) * 0.8)
#train_data <- x_values[train_indices, ]
#train_outcome <- outcome[train_indices]
test_data <- x_values[-train_indices, ]
#train_data <- x_values[train_indices, ]
#train_outcome <- outcome[train_indices]
test_data <- x_values[-train_indices, ]
x_values <- data[, c("Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI", "DiabetesPedigreeFunction", "Age")]
train_indices <- sample(1:nrow(data), nrow(data) * 0.8)
#train_data <- x_values[train_indices, ]
#train_outcome <- outcome[train_indices]
test_data <- x_values[-train_indices, ]
train_dataset <- sample(1:nrow(data), nrow(data) * 0.8)
binary_predictions <- ifelse(predicted > 0.5, 1, 0)
# For example, you can calculate the accuracy
accuracy <- sum(binary_predictions == test_outcome) / length(binary_predictions)
# Extract coefficient values (excluding the intercept)
coefs <- coef(model)[-1]
# Create a data frame of coefficients
coef_df <- data.frame(variable = names(coefs), coefficient = coefs)
# Plot the logistic regression coefficients
ggplot(coef_df, aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "steelblue") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
ggplot(data.frame(variable = names(coefficients), coefficient = coefficients),
aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "blue") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
ggplot(coef_df, aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "blue") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
train_outcome <- outcome[train_dataset]
ggplot(coef_df, aes(x = variable, y = coefficient)) +
geom_bar(stat = "identity", fill = "red") +
xlab("Variable") +
ylab("Coefficient") +
ggtitle("Logistic Regression Coefficients")
View(data)
View(coef_df)
(
rm(list = ls())
library(ggplot2)
library(ggplot2)
library(dplyr)
install.packages("ggplot2")
install.packages("dplyr")
install.packages("glmnet")
